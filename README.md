<img width="1920" height="1024" alt="App page main" src="https://github.com/user-attachments/assets/dec82e9c-79ed-46be-849f-c8b7aa6285d4" />

**App Live Demo:** :--

https://github.com/user-attachments/assets/ef5f35fc-e42a-40b1-8f05-c3fb26a35afd


# ğŸ”¬ AI Researcher Agent / AI Research Saathi Agent ğŸ¤–

> **Discover cuttingâ€‘edge research papers from arXiv with the power of AI**

ğŸš€ **Live App:** [https://ai-research-saathi-agent.streamlit.app/](https://ai-research-saathi-agent.streamlit.app/)

---

## ğŸ“Œ Project Announcement

ğŸ‰ **Today I built a new endâ€‘toâ€‘end AI project â€“ *AI Researcher Agent (AI Research Saathi Agent)***.

This project is an **AIâ€‘powered research assistant** designed for students, researchers, and AI enthusiasts. It helps users **search, analyze, summarize, and interact with research papers from arXiv** using both **offline AI logic** and **multiple LLM providers**.

The app follows a **productionâ€‘grade architecture** with a FastAPI backend and a Streamlit frontend, deployed independently and connected via secure APIs.

---

## ğŸ¯ Purpose & Vision

Research papers are powerful but timeâ€‘consuming to read. This app aims to:

* ğŸ” Quickly **search relevant arXiv papers** by topic
* ğŸ§  Provide **AIâ€‘generated summaries & key insights**
* ğŸ’¬ Enable **chatâ€‘based Q&A** on individual papers
* ğŸ‘¶ Support **ELI5 (Explain Like Iâ€™m 5)** explanations
* ğŸ”Œ Work **offline** or with **multiple LLM providers**
* ğŸ“š Help users **build reading lists & alerts**

The goal is to act as a **personal AI research companion**.

---

## ğŸ§± Highâ€‘Level Architecture

```
[ Streamlit Frontend ]  â†’  [ FastAPI Backend ]  â†’  [ arXiv API ]
           |                     |
           |                     â””â”€ AI Services (Offline / OpenAI / Groq / Anthropic / Gemini)
           |
           â””â”€ UI, Filters, Chat, Summaries, Reading List
```

### ğŸ”¹ Frontend

* **Streamlit (streamlit_app.py)**
* Deployed on **Streamlit Cloud**

### ğŸ”¹ Backend

* **FastAPI (server.py)**
* Deployed on **Render**

---

## âš™ï¸ Core Components Explained

### 1ï¸âƒ£ FastAPI Backend (`server.py`)

The backend exposes clean REST APIs consumed by the Streamlit frontend.

#### ğŸ”— Available Endpoints

* **`GET /health`**
  Health check endpoint to verify backend availability.

* **`GET /search`**
  Searches arXiv using a topic query and returns parsed paper entries.

* **`POST /summarize`**
  Generates AI summaries of papers.

  * Modes: `default`, `eli5`
  * Providers: `offline`, `openai`, `groq`, `anthropic`, `gemini`

* **`POST /chat`**
  Chat with a research paper using its abstract/context.

  * Maintains conversation history (clientâ€‘side)

The backend uses **LangChain tool wrappers** for structured integration.

---

### 2ï¸âƒ£ arXiv Integration (`arxiv_tool.py`)

This module handles all arXiv interactions.

#### ğŸ” Search Flow

* Normalizes keywords (`AND`, `OR`, `NOT`)
* Builds arXiv Atom API query
* Fetches XML response
* Parses and extracts:

  * Title
  * Abstract
  * Authors
  * Categories
  * PDF link
  * Published & updated dates

#### ğŸ§° LangChain Tool

```python
@tool
def arxiv_search(topic):
    return {"entries": [...]}
```

This allows future agentâ€‘based extensions.

---

### 3ï¸âƒ£ AI Services Layer (`ai_services.py`)

This is the **brain of the application**.

#### ğŸ“´ Offline AI (No API Key Required)

* **Summarization**

  * Sentence splitting
  * Token frequency scoring
  * Topâ€‘sentence extraction
  * Key insight heuristics

* **ELI5 Mode**

  * Simplifies vocabulary
  * Shortens long sentences

* **Offline Chat**

  * Finds sentences with highest keyword overlap
  * Contextâ€‘aware responses

#### ğŸŒ Online LLM Providers (Optional)

If API keys are available, the app seamlessly switches to:

* OpenAI
* Groq
* Anthropic
* Google Gemini

All LLM responses are **normalized** into:

```json
{
  "summary": "...",
  "key_insights": ["..."],
  "bullets": ["..."]
}
```

Fallback logic ensures the app **always works**, even offline.

---

### 4ï¸âƒ£ Streamlit Frontend (`streamlit_app.py`)

The frontend provides a **polished, interactive research UI**.

#### ğŸ§­ Sidebar Features

* Backend health check
* Provider selection (offline / LLMs)
* ELI5 toggle
* Temperature slider (UIâ€‘only)
* Runtime API key input
* Max results selector
* Popular topic buttons
* Alerts & Reading List (persisted in `alerts_store.json`)
* Advanced filters:

  * Date range
  * Author keyword
  * Categories
  * Sorting

#### ğŸ–¥ï¸ Main Interface

* Search input â†’ calls `/search`
* Results rendered as **paper cards**
* Clientâ€‘side filtering & sorting

Each paper supports:

* ğŸ§  **AI Summary** â†’ `/summarize`
* ğŸ’¬ **Chat with Paper** â†’ `/chat`
* ğŸ“¥ **Save to Reading List**
* ğŸ“„ **PDF Link**

#### âœ¨ Extra Features

* Streaming wordâ€‘byâ€‘word chat rendering
* JSON & TXT export of results
* Personalized recommendations (keyword overlap)
* Sideâ€‘byâ€‘side paper comparison
* Welcome cards & feature highlights
* Footer with developer credit

---

### 5ï¸âƒ£ CLI Tool (`ai_researcher.py`)

A lightweight commandâ€‘line interface to search arXiv directly.

```bash
python ai_researcher.py "transformer models" --max-results 5
```

Outputs clean, formatted JSON in the terminal.

---

### 6ï¸âƒ£ Testing (`test_api.py`)

Simple automated checks using `requests`:

* `/health`
* `/search` with sample topics

Ensures backend reliability.

---

## ğŸ—‚ï¸ Data Models

### ğŸ“„ Paper Entry

```json
{
  "title": "...",
  "summary": "...",
  "authors": ["..."],
  "categories": ["..."],
  "pdf": "...",
  "published": "...",
  "updated": "..."
}
```

### ğŸ§  Summarization Response

```json
{
  "summary": "...",
  "key_insights": ["..."],
  "bullets": ["..."]
}
```

### ğŸ’¬ Chat Response

```json
{
  "answer": "..."
}
```

---

## â–¶ï¸ Running Locally

### Backend

```bash
python -m uvicorn server:app --reload --host 127.0.0.1 --port 8001
```

### Frontend

```bash
streamlit run streamlit_app.py
```

### Test APIs

```bash
python test_api.py
```

---

## ğŸ“¦ Tech Stack

* Python
* FastAPI
* Streamlit
* Uvicorn
* Requests
* LangChain (tool abstraction)
* arXiv API
* Optional LLM SDKs (OpenAI, Groq, Anthropic, Gemini)

---

## ğŸŒŸ Why This Project Matters

This project demonstrates:

* âœ… Realâ€‘world **frontendâ€“backend separation**
* âœ… APIâ€‘driven AI architecture
* âœ… Graceful offline â†’ online AI fallback
* âœ… Clean modular design
* âœ… Production deployment (Render + Streamlit Cloud)

Itâ€™s not just a demo â€” itâ€™s a **scalable AI research platform**.

---

## ğŸ‘¨â€ğŸ’» Developer

**Abhishek Kumar (Abhi Yadav)**
AI & Data Science Aspirant | Building practical AI products

---

â­ If you like this project, donâ€™t forget to **star the repo** and share feedback!
