<img width="1920" height="1024" alt="App page main" src="https://github.com/user-attachments/assets/dec82e9c-79ed-46be-849f-c8b7aa6285d4" />

**App Live Demo:** :--

https://github.com/user-attachments/assets/ef5f35fc-e42a-40b1-8f05-c3fb26a35afd


 # ğŸ”¬ AI Researcher Agent / AI Research Saathi Agent ğŸ¤–

> **Discover cuttingâ€‘edge research papers from arXiv with the power of AI**

ğŸš€ **Live App:** [https://ai-research-saathi-agent.streamlit.app/](https://ai-research-saathi-agent.streamlit.app/)

---

## ğŸ“Œ Project Announcement

ğŸ‰ **Today I built a new endâ€‘toâ€‘end AI project â€“ *AI Researcher Agent (AI Research Saathi Agent)***.

This project is an **AIâ€‘powered research assistant** designed for students, researchers, and AI enthusiasts. It helps users **search, analyze, summarize, and interact with research papers from arXiv** using both **offline AI logic** and **multiple LLM providers**.

The app follows a **productionâ€‘grade architecture** with a FastAPI backend and a Streamlit frontend, deployed independently and connected via secure APIs.

---

## ğŸ¯ Purpose & Vision

Research papers are powerful but timeâ€‘consuming to read. This app aims to:

* ğŸ” Quickly **search relevant arXiv papers** by topic
* ğŸ§  Provide **AIâ€‘generated summaries & key insights**
* ğŸ’¬ Enable **chatâ€‘based Q&A** on individual papers
* ğŸ‘¶ Support **ELI5 (Explain Like Iâ€™m 5)** explanations
* ğŸ”Œ Work **offline** or with **multiple LLM providers**
* ğŸ“š Help users **build reading lists & alerts**

The goal is to act as a **personal AI research companion**.

---

## ğŸ§± Highâ€‘Level Architecture

```
[ Streamlit Frontend ]  â†’  [ FastAPI Backend ]  â†’  [ arXiv API ]
           |                     |
           |                     â””â”€ AI Services (Offline / OpenAI / Groq / Anthropic / Gemini)
           |
           â””â”€ UI, Filters, Chat, Summaries, Reading List
```

### ğŸ”¹ Frontend

* **Streamlit (streamlit_app.py)**
* Deployed on **Streamlit Cloud**

### ğŸ”¹ Backend

* **FastAPI (server.py)**
* Deployed on **Render**

---

## âš™ï¸ Core Components Explained

### 1ï¸âƒ£ FastAPI Backend (`server.py`)

The backend exposes clean REST APIs consumed by the Streamlit frontend.

#### ğŸ”— Available Endpoints

* **`GET /health`**
  Health check endpoint to verify backend availability.

* **`GET /search`**
  Searches arXiv using a topic query and returns parsed paper entries.

* **`POST /summarize`**
  Generates AI summaries of papers.

  * Modes: `default`, `eli5`
  * Providers: `offline`, `openai`, `groq`, `anthropic`, `gemini`

* **`POST /chat`**
  Chat with a research paper using its abstract/context.

  * Maintains conversation history (clientâ€‘side)

The backend uses **LangChain tool wrappers** for structured integration.

---

### 2ï¸âƒ£ arXiv Integration (`arxiv_tool.py`)

This module handles all arXiv interactions.

#### ğŸ” Search Flow

* Normalizes keywords (`AND`, `OR`, `NOT`)
* Builds arXiv Atom API query
* Fetches XML response
* Parses and extracts:

  * Title
  * Abstract
  * Authors
  * Categories
  * PDF link
  * Published & updated dates

#### ğŸ§° LangChain Tool

```python
@tool
def arxiv_search(topic):
    return {"entries": [...]}
```

This allows future agentâ€‘based extensions.

---

### 3ï¸âƒ£ AI Services Layer (`ai_services.py`)

This is the **brain of the application**.

#### ğŸ“´ Offline AI (No API Key Required)

* **Summarization**

  * Sentence splitting
  * Token frequency scoring
  * Topâ€‘sentence extraction
  * Key insight heuristics

* **ELI5 Mode**

  * Simplifies vocabulary
  * Shortens long sentences

* **Offline Chat**

  * Finds sentences with highest keyword overlap
  * Contextâ€‘aware responses

#### ğŸŒ Online LLM Providers (Optional)

If API keys are available, the app seamlessly switches to:

* OpenAI
* Groq
* Anthropic
* Google Gemini

All LLM responses are **normalized** into:

```json
{
  "summary": "...",
  "key_insights": ["..."],
  "bullets": ["..."]
}
```

Fallback logic ensures the app **always works**, even offline.

---

### 4ï¸âƒ£ Streamlit Frontend (`streamlit_app.py`)

The frontend provides a **polished, interactive research UI**.

#### ğŸ§­ Sidebar Features

* Backend health check
* Provider selection (offline / LLMs)
* ELI5 toggle
* Temperature slider (UIâ€‘only)
* Runtime API key input
* Max results selector
* Popular topic buttons
* Alerts & Reading List (persisted in `alerts_store.json`)
* Advanced filters:

  * Date range
  * Author keyword
  * Categories
  * Sorting

#### ğŸ–¥ï¸ Main Interface

* Search input â†’ calls `/search`
* Results rendered as **paper cards**
* Clientâ€‘side filtering & sorting

Each paper supports:

* ğŸ§  **AI Summary** â†’ `/summarize`
* ğŸ’¬ **Chat with Paper** â†’ `/chat`
* ğŸ“¥ **Save to Reading List**
* ğŸ“„ **PDF Link**

#### âœ¨ Extra Features

* Streaming wordâ€‘byâ€‘word chat rendering
* JSON & TXT export of results
* Personalized recommendations (keyword overlap)
* Sideâ€‘byâ€‘side paper comparison
* Welcome cards & feature highlights
* Footer with developer credit

---

### 5ï¸âƒ£ CLI Tool (`ai_researcher.py`)

A lightweight commandâ€‘line interface to search arXiv directly.

```bash
python ai_researcher.py "transformer models" --max-results 5
```

Outputs clean, formatted JSON in the terminal.

---

### 6ï¸âƒ£ Testing (`test_api.py`)

Simple automated checks using `requests`:

* `/health`
* `/search` with sample topics

Ensures backend reliability.

---

## ğŸ—‚ï¸ Data Models

### ğŸ“„ Paper Entry

```json
{
  "title": "...",
  "summary": "...",
  "authors": ["..."],
  "categories": ["..."],
  "pdf": "...",
  "published": "...",
  "updated": "..."
}
```

### ğŸ§  Summarization Response

```json
{
  "summary": "...",
  "key_insights": ["..."],
  "bullets": ["..."]
}
```

### ğŸ’¬ Chat Response

```json
{
  "answer": "..."
}
```

---

## â–¶ï¸ Running Locally

### Backend

```bash
python -m uvicorn server:app --reload --host 127.0.0.1 --port 8001
```

### Frontend

```bash
streamlit run streamlit_app.py
```

### Test APIs

```bash
python test_api.py
```

---

## ğŸ“¦ Tech Stack

* Python
* FastAPI
* Streamlit
* Uvicorn
* Requests
* LangChain (tool abstraction)
* arXiv API
* Optional LLM SDKs (OpenAI, Groq, Anthropic, Gemini)

---

## ğŸŒŸ Why This Project Matters

This project demonstrates:

* âœ… Realâ€‘world **frontendâ€“backend separation**
* âœ… APIâ€‘driven AI architecture
* âœ… Graceful offline â†’ online AI fallback
* âœ… Clean modular design
* âœ… Production deployment (Render + Streamlit Cloud)

Itâ€™s not just a demo â€” itâ€™s a **scalable AI research platform**.

---

## ğŸ‘¨â€ğŸ’» Developer

**Abhishek Kumar (Abhi Yadav)**
AI & Data Science Aspirant | Building practical AI products

---

â­ If you like this project, donâ€™t forget to **star the repo** and share feedback!

---

## ğŸ§  LangGraph Binary Tree â€“ How the App Works (User Journey)

Below is a **LangGraph-style Binary Tree representation** explaining **how a new user starts and interacts with the AI Researcher Agent**. This shows decision points, flow control, and fallback logic clearly.

```
                          ğŸ‘¤ New User Opens App
                                   â”‚
                                   â–¼
                       ğŸ–¥ï¸ Streamlit Frontend Loads
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                             â–¼
          ğŸ” User Enters Search Topic        âŒ No Topic Entered
                    â”‚                             â”‚
                    â–¼                             â–¼
        â–¶ï¸ Call /search API (FastAPI)     ğŸ´ Show Welcome + Tips
                    â”‚
                    â–¼
        ğŸŒ arXiv API Fetch (Atom XML)
                    â”‚
                    â–¼
        ğŸ“„ Parsed Research Papers Returned
                    â”‚
                    â–¼
          ğŸ§¾ Display Paper Cards (UI)
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼
ğŸ§  User Clicks "AI Summary"   ğŸ’¬ User Clicks "Chat"
        â”‚                       â”‚
        â–¼                       â–¼
â–¶ï¸ Call /summarize API     â–¶ï¸ Call /chat API
        â”‚                       â”‚
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Provider? â”‚        â”‚ LLM Provider? â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚YES                    â”‚YES
        â–¼                       â–¼
 ğŸ¤– Online LLM Response     ğŸ¤– Online LLM Response
        â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
          ğŸ”„ Normalize AI Output
                   â”‚
                   â–¼
        ğŸ§  Summary / Answer Returned
                   â”‚
                   â–¼
          ğŸ–¥ï¸ Render in Streamlit UI
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼
ğŸ“¥ Save to Reading List   ğŸ“¤ Export / Compare
        â”‚                     â”‚
        â–¼                     â–¼
ğŸ”” Alerts & Recommender   ğŸ”š User Session Ends
```

---

### ğŸ§© Binary Decision Logic Explained

* **Decision Node 1:** Did the user enter a search topic?

  * âŒ No â†’ Show welcome cards and guidance
  * âœ… Yes â†’ Proceed to arXiv search

* **Decision Node 2:** Does the user want a summary or chat?

  * Summary â†’ `/summarize`
  * Chat â†’ `/chat`

* **Decision Node 3:** Is an LLM provider configured?

  * âŒ No â†’ Offline AI logic (heuristics)
  * âœ… Yes â†’ OpenAI / Groq / Anthropic / Gemini

This structure ensures **fault tolerance**, **offline usability**, and **scalable agent-based reasoning**, which aligns perfectly with **LangGraph design philosophy**.

---

### ğŸ§  Why This Fits LangGraph Concepts

* ğŸ” **Stateful Flow**: Session state + chat history
* ğŸŒ³ **Graph Nodes**: Search â†’ Summarize / Chat
* ğŸ”€ **Conditional Edges**: LLM vs Offline
* ğŸ›‘ **Safe Fallbacks**: App always responds
* ğŸ§© **Composable Tools**: arXiv search as a tool node

This binary-tree-like LangGraph flow makes the app **agent-ready** for future extensions like multi-agent research, critique agents, or paper comparison agents.

---

## â¤ï¸ **Made with Passion by Abhishek Yadav & Open-Source Contributors!** ğŸš€âœ¨


<h1 align="center">Â© LICENSE <img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Telegram-Animated-Emojis/main/Symbols/Check%20Box%20With%20Check.webp" alt="Check Box With Check" width="25" height="25" /></h1>

<table align="center">
  <tr>
     <td>
       <p align="center"> <img src="https://github.com/malivinayak/malivinayak/blob/main/LICENSE-Logo/MIT.png?raw=true" width="80%"></img>
    </td>
    <td> 
      <img src="https://img.shields.io/badge/License-MIT-yellow.svg"/> <br> 
This project is licensed under <a href="./LICENSE">MIT</a>. <img width=2300/>
    </td>
  </tr>
</table>

<img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="900">



 
 <hr>

<div align="center">
<a href="#"><img src="assets/githubgif.gif" width="150"></a>
	
### **Thanks for checking out my GitHub Profile!**  

 ## ğŸ’Œ Sponser

  [![BuyMeACoffee](https://img.buymeacoffee.com/button-api/?text=Buymeacoffee&emoji=&slug=codingstella&button_colour=FFDD00&font_colour=000000&font_family=Comic&outline_colour=000000&coffee_colour=ffffff)](https://www.buymeacoffee.com/abhishekkumar62000)

## ğŸ‘¨â€ğŸ’» Developer Information  
**Created by:** **Abhishek Kumar**  
**ğŸ“§ Email:** [abhiydv23096@gmail.com](mailto:abhiydv23096@gmail.com)  
**ğŸ”— LinkedIn:** [Abhishek Kumar](https://www.linkedin.com/in/abhishek-kumar-70a69829a/)  
**ğŸ™ GitHub Profile:** [@abhishekkumar62000](https://github.com/abhishekkumar62000)

<p align="center">
  <img src="https://github.com/user-attachments/assets/6283838c-8640-4f22-87d4-6d4bfcbbb093" width="120" style="border-radius: 50%;">
</p>
</div>  


`Don't forget to give A star to this repository â­`


`ğŸ‘ğŸ» All Set! ğŸ’Œ`

</div>

---
